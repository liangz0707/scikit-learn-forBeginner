{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Model selection: choosing estimators and their parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.Score, and cross-validated scores\n",
    "As we have seen, every estimator exposes a score method that can judge the quality of the fit (or the prediction) on new data. Bigger is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97999999999999998"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets , svm\n",
    "digits = datasets.load_digits()\n",
    "X_digits = digits.data\n",
    "y_digits = digits.target\n",
    "svc = svm.SVC(C=1,kernel='linear')\n",
    "svc.fit(X_digits[:-100],y_digits[:-100]).score(X_digits[-100:],y_digits[-100:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better measure of prediction accuracy (which we can use as a proxy for goodness of fit of the model), we can successively split the data in folds that we use for training and testing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "X_folds = np.array_split(X_digits,3)#平均分成了三分\n",
    "y_folds = np.array_split(y_digits,3)\n",
    "scores = list()\n",
    "for k in range(3):\n",
    "    X_train = list(X_folds) #使用list来进行复制\n",
    "    X_test  = X_train.pop(k)\n",
    "    X_train = np.concatenate(X_train)\n",
    "    y_train = list(y_folds)\n",
    "    y_test  = y_train.pop(k)\n",
    "    y_train = np.concatenate(y_train) #将list连接成一个ndarray\n",
    "    print len(X_train)\n",
    "    scores.append(svc.fit(X_train, y_train).score(X_test, y_test))\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Cross-validation generators\n",
    "The code above to split data in train and test sets is tedious to write. Scikit-learn exposes cross-validation generators to generate list of indices for this purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
